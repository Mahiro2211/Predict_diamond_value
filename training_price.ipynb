{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab10154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from data_changed import * # 里头的items是我们用来训练的\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import joblib\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10152c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/douhuanmin/zhangyi_homework/final'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88151127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([43136, 12]), torch.Size([10784, 12]), torch.Size([43136]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_mean = items.mean(dim=0)\n",
    "items_std = items.std(dim=0)\n",
    "items_normalized = (items - items_mean)/items_std\n",
    "items_normalized\n",
    "x = items_normalized[:, :-1]  # 特征张量\n",
    "y = items_normalized[:, -1]   # 标签张量\n",
    "train_size = int(0.8 * len(items_normalized))\n",
    "train_x, test_x = x[:train_size], x[train_size:]\n",
    "train_y, test_y = y[:train_size], y[train_size:]\n",
    "scaler = (items_mean, items_std)\n",
    "joblib.dump(scaler , \"diamond_price_scaler.pkl\")\n",
    "train_x.size() , test_x.size() , train_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eef26f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1154\n",
      "Epoch [200/1000], Loss: 0.1072\n",
      "Epoch [300/1000], Loss: 0.1054\n",
      "Epoch [400/1000], Loss: 0.1045\n",
      "Epoch [500/1000], Loss: 0.1038\n",
      "Epoch [600/1000], Loss: 0.1033\n",
      "Epoch [700/1000], Loss: 0.1029\n",
      "Epoch [800/1000], Loss: 0.1025\n",
      "Epoch [900/1000], Loss: 0.1022\n",
      "Epoch [1000/1000], Loss: 0.1021\n",
      "Test Loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "class DiamondPricePredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim).double()  # 将权重张量和偏置张量的数据类型改为torch.float64\n",
    "        self.fc2 = nn.Linear(hidden_dim , 512).double()\n",
    "        self.fc3 = nn.Linear(512 , hidden_dim).double()\n",
    "        self.fc4 = nn.Linear(hidden_dim ,output_dim).double()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "input_dim = 12\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "model = DiamondPricePredictor(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "# 训练模型\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # 前向传播\n",
    "    outputs = model(train_x)\n",
    "    loss = criterion(outputs, train_y.view(-1, 1))\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 打印损失值\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# 在测试集上评估模型\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_x)\n",
    "    test_loss = criterion(test_outputs, test_y.view(-1, 1))\n",
    "    print('Test Loss: {:.4f}'.format(test_loss.item()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ed0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'diamond_price.pt')\n",
    "from data_need_pre import *\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_x)\n",
    "    test_loss = criterion(test_outputs, test_y.view(-1, 1))\n",
    "    print('Test Loss: {:.4f}'.format(test_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa77030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price 1: $770.92\n",
      "Predicted price 2: $38953.07\n",
      "Predicted price 3: $42561.06\n",
      "Predicted price 4: $1000.56\n",
      "Predicted price 5: $76711.12\n",
      "Predicted price 6: $31357.99\n",
      "Predicted price 7: $34515.51\n",
      "Predicted price 8: $40731.79\n",
      "Predicted price 9: $73338.68\n",
      "Predicted price 10: $49776.88\n",
      "Predicted price 11: $4300.86\n",
      "Predicted price 12: $4692.57\n",
      "Predicted price 13: $4366.44\n",
      "Predicted price 14: $6274.51\n",
      "Predicted price 15: $8495.88\n",
      "Predicted price 16: $21949.81\n",
      "Predicted price 17: $8314.60\n",
      "Predicted price 18: $20644.83\n",
      "Predicted price 19: $41882.95\n",
      "Predicted price 20: $32875.65\n",
      "<class 'numpy.ndarray'>\n",
      "[770.9192896448731, 38953.06890561105, 42561.055230242, 1000.5572855417377, 76711.11654003663, 31357.985027028826, 34515.512365819384, 40731.79168350308, 73338.67692321925, 49776.876216089455, 4300.864309264187, 4692.567285986468, 4366.435578822737, 6274.512854956334, 8495.880988131215, 21949.809337279723, 8314.599305207896, 20644.82655849697, 41882.95285497815, 32875.64617205613]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载模型和归一化器\n",
    "model = torch.load('diamond_price.pt')\n",
    "scaler = joblib.load('diamond_price_scaler.pkl')\n",
    "\n",
    "# 准备输入数据\n",
    "input_data = data_need_pred\n",
    "\n",
    "# 计算输入数据的均值和标准差\n",
    "input_data_mean = input_data.mean(dim=0, keepdim=True)\n",
    "input_data_std = input_data.std(dim=0, keepdim=True)\n",
    "\n",
    "# 对输入数据进行归一化处理\n",
    "input_data_normalized = (input_data - input_data_mean) / input_data_std\n",
    "\n",
    "# 将输入数据的数据类型转换为与模型权重相同的数据类型\n",
    "input_data_normalized = input_data_normalized.to(model.fc1.weight.dtype)\n",
    "\n",
    "# 预测归一化的价格\n",
    "predicted_price_normalized = model(input_data_normalized)\n",
    "\n",
    "# 反归一化输出价格\n",
    "predicted_price = predicted_price_normalized * scaler[1][-1] + scaler[0][-1]\n",
    "\n",
    "# 打印预测的价格\n",
    "predicted_price_np = predicted_price.detach().numpy()\n",
    "for i in range(len(predicted_price_np)):\n",
    "    print('Predicted price {}: ${:.2f}'.format(i+1, float(predicted_price_np[i])))\n",
    "print(type(predicted_price_np))\n",
    "predicted_price_np = predicted_price_np.sum(axis=1)\n",
    "predicted_price_np = predicted_price_np.tolist()\n",
    "print(predicted_price_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2789cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douhuanmin/anaconda3/envs/env/lib/python3.10/site-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "predicted_price_np = predicted_price_np\n",
    "predicted_price_np_rounded = [round(x) for x in predicted_price_np]\n",
    "\n",
    "f['price'] = {k:predicted_price_np[k] for k in range(len(f['price']))}\n",
    "# 将数据框写入到Excel文件中（使用XlsxWriter作为引擎）\n",
    "writer = pd.ExcelWriter('输出.xlsx', engine='xlsxwriter')\n",
    "f.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "# 获取workbook对象\n",
    "workbook = writer.book\n",
    "\n",
    "# 关闭Excel写入对象并保存文件\n",
    "writer.close()\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2645f35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted_price_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "943719b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[ 2.4247e-01, -6.2386e-02,  4.4015e-03, -2.7621e-02, -4.1399e-02,\n",
      "         -7.8320e-02, -4.5458e-03, -4.6089e-02,  8.1657e-02,  1.1223e-01,\n",
      "         -2.4927e-02, -6.9187e-02],\n",
      "        [ 1.9825e-01,  6.9036e-03, -3.1057e-02,  1.4953e-01, -2.7676e-02,\n",
      "         -6.9599e-02,  2.8573e-02,  1.0899e-01,  1.3087e-01,  1.9208e-03,\n",
      "         -6.2994e-05,  1.1762e-01],\n",
      "        [-1.9608e-01,  1.4459e-01,  2.0527e-01,  1.7390e-01, -6.0174e-02,\n",
      "         -3.6162e-02,  6.2043e-02, -1.7717e-02, -6.3689e-02,  9.5190e-02,\n",
      "          4.2009e-02,  7.0004e-02],\n",
      "        [-2.1911e-01,  1.6624e-01, -1.2274e-01, -1.1540e-01, -5.0218e-02,\n",
      "          5.5213e-02, -1.0333e-01, -7.4219e-02,  1.7399e-01,  2.1846e-02,\n",
      "         -9.9396e-02,  2.3390e-01],\n",
      "        [-1.5028e-01, -1.2097e-01,  6.9753e-02, -7.3414e-02, -8.5725e-02,\n",
      "          1.1543e-01,  7.0911e-03, -6.1226e-02,  1.4229e-01, -6.3534e-02,\n",
      "         -2.5177e-02, -3.4797e-02],\n",
      "        [-3.7325e-02,  8.1390e-02, -1.5626e-01, -4.1698e-02, -1.4446e-01,\n",
      "          1.4272e-01,  1.1364e-01,  1.4356e-01, -7.0295e-02, -1.0448e-01,\n",
      "          1.9540e-01, -1.0683e-01],\n",
      "        [-1.3938e-01, -1.0655e-01,  7.2277e-02,  1.7532e-01,  1.8818e-01,\n",
      "          7.2339e-03, -1.3118e-01,  7.0850e-02,  8.0622e-04, -3.2432e-02,\n",
      "          5.3799e-02,  4.1588e-02],\n",
      "        [ 6.4174e-02, -1.3038e-01,  1.0801e-01,  9.2529e-02,  4.6939e-02,\n",
      "         -1.0351e-01, -5.3315e-02,  1.0295e-01, -3.3129e-02,  6.2186e-02,\n",
      "          9.2662e-03,  7.1323e-02],\n",
      "        [ 1.4193e-01, -9.1325e-02, -1.6970e-01, -1.9536e-01,  1.0622e-01,\n",
      "          4.7905e-02,  1.3141e-01, -3.5708e-02, -1.1586e-01,  4.7808e-03,\n",
      "          1.0217e-01, -4.0702e-03],\n",
      "        [-1.4895e-01,  7.6237e-02, -1.2178e-01,  2.5899e-01, -3.7134e-02,\n",
      "          1.9208e-02, -1.2224e-02, -8.1159e-02,  1.0763e-01,  7.5197e-03,\n",
      "          5.2701e-02,  1.8612e-01],\n",
      "        [ 2.5301e-01, -4.7560e-02,  1.1186e-01,  2.8725e-01, -1.0619e-01,\n",
      "         -9.1516e-03, -3.1994e-02, -4.7552e-02,  1.7535e-01, -1.1966e-01,\n",
      "          9.6904e-02,  1.5737e-01],\n",
      "        [ 2.1301e-02, -4.9162e-02, -1.6820e-01, -1.5863e-01,  2.5338e-02,\n",
      "          1.1112e-01, -3.1545e-02, -9.6178e-02, -5.4332e-02,  1.1115e-01,\n",
      "         -8.3495e-03,  1.3323e-01],\n",
      "        [ 4.5845e-02, -7.4244e-02,  8.9066e-02,  2.2681e-01, -7.7853e-02,\n",
      "         -6.2117e-02, -6.2613e-02, -4.5416e-02,  1.1320e-01, -4.3945e-02,\n",
      "          4.4451e-02,  9.4659e-02],\n",
      "        [ 1.5748e-01,  1.6574e-01, -6.5704e-02,  1.2136e-01,  7.1127e-02,\n",
      "          6.0886e-02,  3.4792e-02, -1.2294e-01,  2.5034e-02,  2.2410e-02,\n",
      "         -6.0041e-02, -8.3233e-02],\n",
      "        [ 1.9650e-01,  5.9764e-02,  1.2440e-01,  2.0166e-01,  1.1580e-02,\n",
      "          1.4908e-01, -1.7042e-01,  1.1053e-01,  1.5011e-01,  9.8683e-02,\n",
      "         -1.4030e-01, -6.5366e-02],\n",
      "        [ 7.0431e-02, -8.3522e-02,  1.3015e-01, -2.3720e-02,  1.9692e-01,\n",
      "         -4.8233e-04,  1.0118e-02,  2.2511e-02, -1.2773e-02, -3.6119e-02,\n",
      "          1.3405e-01, -3.9528e-02],\n",
      "        [-1.3293e-01, -8.2632e-02,  8.9571e-02, -2.6705e-03,  6.1208e-02,\n",
      "         -9.0661e-03,  6.0037e-02, -9.3237e-02,  1.6599e-02,  2.8282e-02,\n",
      "         -6.8108e-02, -2.2697e-02],\n",
      "        [-8.6749e-02,  1.4201e-02,  2.2205e-01, -1.9574e-01, -6.2542e-02,\n",
      "          1.1423e-01, -1.4598e-01, -1.1334e-01,  7.7205e-02,  1.1905e-01,\n",
      "          1.5257e-01,  9.9524e-02],\n",
      "        [ 6.3059e-02,  1.9528e-02, -1.4690e-01,  2.6891e-02,  8.5782e-02,\n",
      "         -1.5391e-02,  1.5358e-02,  3.0203e-03, -2.0237e-02,  7.7513e-02,\n",
      "          1.5583e-01,  5.7934e-02],\n",
      "        [ 1.9283e-01, -9.2033e-02, -2.4030e-01, -1.8045e-01, -1.1709e-01,\n",
      "         -7.4872e-02, -1.0376e-01,  6.9878e-02,  1.1919e-01,  1.1953e-01,\n",
      "          1.2381e-01,  5.8006e-02],\n",
      "        [-9.9411e-02,  1.8635e-02, -5.3765e-03,  6.7571e-02,  3.5475e-03,\n",
      "         -5.3499e-03,  5.3875e-02, -1.4653e-02, -1.2725e-02,  5.5612e-03,\n",
      "          9.5586e-02,  5.3198e-02],\n",
      "        [-1.9245e-01, -2.3966e-03,  1.0093e-01, -1.5798e-01, -2.8189e-03,\n",
      "         -5.5469e-02,  1.1069e-01,  1.4612e-02,  1.6051e-01, -3.7262e-02,\n",
      "         -2.4142e-02, -6.3454e-02],\n",
      "        [-2.4822e-01,  7.4754e-02, -1.6481e-01,  3.0394e-01, -1.3724e-01,\n",
      "         -6.6523e-02, -3.8465e-02,  1.4671e-01, -8.1477e-02,  1.2455e-01,\n",
      "         -4.2686e-03, -1.2886e-02],\n",
      "        [-1.0117e-01,  5.2832e-03,  1.6226e-01, -5.1138e-02, -7.3814e-02,\n",
      "         -3.6256e-02,  1.4926e-01,  1.5214e-02, -1.6019e-02, -2.0345e-02,\n",
      "          1.9227e-01, -1.0929e-02],\n",
      "        [ 3.0666e-01, -2.0607e-02, -1.5308e-01,  1.3474e-01,  3.2317e-02,\n",
      "          1.3140e-01,  1.9743e-01,  2.8532e-02,  1.5733e-01, -3.3899e-02,\n",
      "         -5.5786e-02, -1.1113e-01],\n",
      "        [-9.9965e-02, -1.2927e-01, -1.3073e-01,  7.4050e-02, -9.6307e-02,\n",
      "          1.2502e-01, -1.2916e-02, -7.5881e-03,  3.0395e-02,  3.5115e-02,\n",
      "         -7.4942e-02, -8.2764e-02],\n",
      "        [-7.4492e-02,  2.3912e-03, -2.2374e-03,  8.0524e-02,  4.8969e-02,\n",
      "         -2.1886e-02,  2.1308e-02, -5.8418e-02,  6.0062e-02,  6.0291e-02,\n",
      "         -4.4269e-02,  1.9158e-02],\n",
      "        [ 2.6583e-01,  7.6822e-02, -1.6917e-02, -1.2885e-01,  7.3281e-03,\n",
      "         -3.8232e-02, -1.0645e-02,  3.8385e-02, -1.7812e-02,  8.2026e-02,\n",
      "         -1.1950e-02, -3.0623e-02],\n",
      "        [ 1.6071e-01,  4.7332e-04, -1.9379e-01, -1.4483e-02,  6.3300e-02,\n",
      "         -2.5687e-02, -3.2378e-02,  9.8771e-02,  2.6422e-02, -3.8029e-02,\n",
      "          8.8692e-02, -5.7474e-03],\n",
      "        [-3.5440e-02, -1.9272e-02, -3.7684e-02,  4.7863e-02, -3.9443e-02,\n",
      "         -5.0348e-02,  5.2795e-02,  1.1382e-01, -6.5603e-02,  1.8450e-02,\n",
      "         -5.2091e-02,  4.2460e-02],\n",
      "        [ 1.7546e-01,  3.8004e-03,  1.7662e-01,  2.6296e-01, -1.7587e-01,\n",
      "          1.6407e-01, -3.3239e-02,  6.0146e-02, -2.2034e-01,  4.7908e-02,\n",
      "         -4.6212e-02, -1.6577e-01],\n",
      "        [-1.6325e-01, -6.6607e-02,  4.9342e-02, -1.4234e-01, -1.3168e-02,\n",
      "         -6.4377e-02,  8.9840e-02,  1.6268e-01, -1.2092e-01,  3.9180e-02,\n",
      "         -4.8567e-02, -6.1873e-02],\n",
      "        [ 2.5253e-01,  6.2619e-03,  1.1307e-03,  2.1206e-01,  2.3341e-01,\n",
      "          1.4655e-01, -5.0378e-02,  1.3043e-01, -1.2679e-01,  1.3262e-01,\n",
      "          1.6215e-01,  1.2953e-01],\n",
      "        [-6.7198e-02,  3.0620e-02,  1.8293e-01,  2.9109e-01,  1.1440e-01,\n",
      "         -1.0592e-01,  1.5218e-02, -1.2000e-01,  3.0760e-02, -1.1937e-01,\n",
      "         -9.9057e-03, -7.2239e-02],\n",
      "        [ 1.8231e-01,  4.1773e-03,  2.0908e-01, -2.5059e-01, -8.0694e-02,\n",
      "         -3.4001e-03,  8.5596e-02,  3.6354e-02,  3.9158e-02, -2.4110e-02,\n",
      "          7.4092e-02, -1.2492e-01],\n",
      "        [-2.0069e-02, -6.5948e-02, -1.1019e-02,  7.4997e-02, -2.6058e-02,\n",
      "         -6.9448e-02,  1.6795e-01, -6.5415e-02, -4.8471e-02, -3.5943e-02,\n",
      "          1.3216e-01,  8.6824e-02],\n",
      "        [ 1.2172e-01,  1.1269e-02, -1.3312e-01,  1.9345e-01, -1.2548e-03,\n",
      "         -5.6747e-02, -6.2724e-02,  4.7824e-02,  1.0490e-01, -7.3848e-03,\n",
      "          7.4099e-02, -7.6538e-03],\n",
      "        [ 2.0169e-01,  1.3895e-02, -1.3592e-01,  1.4810e-01,  8.2927e-02,\n",
      "          1.2634e-01,  3.7126e-02, -4.8328e-02,  1.6992e-01, -1.0031e-01,\n",
      "         -8.0756e-02,  1.1143e-01],\n",
      "        [ 2.1024e-02,  5.9108e-02,  1.0153e-02, -1.6833e-01, -3.8707e-02,\n",
      "          7.3719e-02, -4.7308e-03,  1.0010e-01, -1.4069e-01, -4.9887e-03,\n",
      "         -3.4694e-02,  4.3529e-02],\n",
      "        [ 2.6379e-01, -2.0546e-02,  1.5770e-02, -2.3948e-01,  3.7159e-03,\n",
      "          6.2108e-02,  1.0309e-02,  5.1732e-02, -1.6413e-02, -3.7090e-02,\n",
      "          9.8524e-02,  3.1608e-02],\n",
      "        [ 1.0991e-01, -6.1126e-02, -1.6787e-01, -1.2465e-01,  4.2988e-02,\n",
      "          4.3633e-02, -2.6090e-02, -3.3884e-02,  1.0243e-01, -7.1293e-03,\n",
      "         -3.0336e-02,  1.8767e-01],\n",
      "        [-1.4373e-01, -1.1638e-01,  5.4644e-02,  3.4683e-02,  6.3961e-02,\n",
      "         -8.9667e-02, -9.8796e-02, -1.1395e-01, -8.2658e-02,  1.1019e-01,\n",
      "          6.2263e-02,  2.0185e-01],\n",
      "        [-1.6945e-01, -1.2310e-01,  1.6483e-01, -7.1348e-02,  7.5221e-02,\n",
      "          1.5658e-02, -9.3740e-02, -9.3795e-02, -6.0090e-02,  8.4872e-02,\n",
      "          7.8453e-02, -1.9135e-02],\n",
      "        [-1.5290e-01,  6.9198e-02,  9.6603e-02,  1.0089e-01, -8.2176e-02,\n",
      "          1.5493e-02,  2.2491e-02, -8.9950e-03,  1.9433e-02,  2.7789e-02,\n",
      "          1.1379e-01, -1.1685e-01],\n",
      "        [ 2.9400e-01, -1.5770e-01, -6.9302e-02, -1.7405e-01,  5.1220e-02,\n",
      "          4.8010e-02,  2.3670e-02,  4.5191e-04, -3.0433e-02,  8.4932e-03,\n",
      "         -4.3393e-02, -4.0835e-02],\n",
      "        [-6.2650e-02,  2.0644e-02,  7.8576e-02,  2.9176e-02,  1.2577e-01,\n",
      "          3.0211e-02,  4.3394e-02, -5.7002e-02,  3.4453e-02, -4.9410e-02,\n",
      "          3.1114e-02, -3.0855e-02],\n",
      "        [-4.1069e-02, -2.5097e-02,  7.3208e-02, -1.1044e-01,  1.3296e-01,\n",
      "         -9.2533e-02, -7.3627e-02,  2.5437e-02,  5.9735e-02,  4.5818e-02,\n",
      "          6.6127e-02,  2.8776e-02],\n",
      "        [-1.0773e-01,  1.7644e-03, -3.1336e-02,  2.5551e-01,  1.7432e-02,\n",
      "         -2.2593e-02,  9.2609e-02,  4.1761e-02, -2.5630e-02, -1.1939e-03,\n",
      "         -3.1142e-02, -4.0748e-02],\n",
      "        [ 1.9679e-01,  1.4286e-01,  2.3654e-01, -1.1782e-01, -1.7229e-01,\n",
      "         -1.2387e-01,  1.1141e-01,  5.4378e-03,  8.3802e-02, -8.1783e-02,\n",
      "         -5.7928e-02,  3.2462e-02],\n",
      "        [-1.2419e-01, -2.2585e-01, -7.7127e-02,  2.5316e-01, -1.3016e-01,\n",
      "          9.4078e-02,  7.2489e-02,  3.1199e-02, -2.9327e-03,  1.3825e-02,\n",
      "         -1.2981e-01,  2.1257e-02],\n",
      "        [-2.2994e-01, -5.6387e-03, -1.3883e-01, -4.6765e-02,  2.0496e-01,\n",
      "          9.5537e-02,  1.5150e-02,  8.8762e-02,  7.7717e-02, -1.2385e-01,\n",
      "         -4.2831e-02, -9.6532e-02],\n",
      "        [-1.9295e-01, -3.5390e-02,  1.3914e-01, -2.0061e-01, -6.4422e-02,\n",
      "         -5.8853e-02, -1.2544e-01, -1.2114e-02,  1.7686e-01, -7.4088e-03,\n",
      "         -1.3557e-02,  1.6063e-01],\n",
      "        [-2.4299e-02, -3.0051e-02, -1.4574e-02, -4.7166e-03, -1.1689e-01,\n",
      "         -7.6205e-02,  1.1080e-01,  6.2251e-02, -1.0667e-01,  2.6914e-02,\n",
      "         -8.3412e-02, -1.5771e-02],\n",
      "        [-1.2344e-01,  6.0840e-02, -2.0206e-01, -9.7557e-02,  5.3552e-02,\n",
      "          1.1840e-01,  1.2449e-01,  2.0361e-02, -2.0460e-01,  6.5013e-02,\n",
      "         -3.4444e-02, -8.6213e-02],\n",
      "        [-1.6799e-01,  8.1389e-02,  1.7705e-01,  2.0383e-01,  1.3095e-01,\n",
      "          4.3136e-02,  4.1022e-03, -7.8297e-02,  8.4152e-02, -9.8327e-02,\n",
      "          1.0829e-01, -4.4532e-02],\n",
      "        [-4.6157e-02, -2.1495e-02,  5.8101e-02,  1.1813e-02,  2.2710e-02,\n",
      "          9.0276e-02, -3.4104e-02, -3.1340e-02,  7.4046e-02, -4.4267e-02,\n",
      "         -2.5538e-02,  9.0470e-02],\n",
      "        [-1.4781e-01, -4.2263e-04,  3.3592e-02,  1.2599e-01, -2.1797e-01,\n",
      "         -3.3826e-02,  8.1078e-02, -2.6051e-02, -1.4114e-02, -2.2589e-02,\n",
      "         -1.2862e-02,  8.7811e-02],\n",
      "        [ 3.7522e-02, -7.8610e-03,  8.2956e-03, -8.4057e-02,  3.1853e-01,\n",
      "          2.6547e-02, -7.4869e-02,  4.0896e-02,  4.6475e-02,  3.9695e-02,\n",
      "         -4.5757e-02, -3.7042e-02],\n",
      "        [ 1.9904e-03,  1.5571e-03, -6.5468e-02,  1.7903e-01, -1.0777e-01,\n",
      "          1.7577e-02,  1.5543e-01,  1.1329e-01, -1.3797e-01,  6.1115e-02,\n",
      "          9.4540e-02,  3.1945e-02],\n",
      "        [-9.8947e-03, -1.0102e-01,  8.8632e-04, -3.7687e-03, -1.6827e-01,\n",
      "          6.7363e-02, -3.9122e-02, -3.5934e-02,  1.5516e-01, -2.5948e-02,\n",
      "         -5.9136e-02, -3.8479e-02],\n",
      "        [ 1.2196e-02, -1.6069e-01,  1.8291e-01,  2.8055e-01,  1.0492e-01,\n",
      "         -1.4690e-01,  3.0227e-02, -1.1162e-02, -1.5062e-01,  6.3624e-02,\n",
      "          9.7218e-02, -3.2756e-02],\n",
      "        [ 3.7509e-02, -3.8366e-02, -1.2645e-01, -7.5020e-02, -8.7281e-03,\n",
      "         -1.4442e-02,  5.9237e-02,  5.5852e-02, -5.5284e-02,  9.9855e-02,\n",
      "          1.1643e-02,  1.7676e-02],\n",
      "        [-4.8842e-02, -1.2809e-01,  2.4139e-02,  1.4869e-01,  1.1054e-01,\n",
      "         -9.3523e-03, -6.6256e-02,  1.0408e-01, -6.7758e-02,  6.6166e-03,\n",
      "         -5.1204e-02,  1.1449e-01],\n",
      "        [ 6.4056e-02,  1.4983e-01,  5.9788e-02,  2.2481e-02, -1.7953e-01,\n",
      "          9.8242e-02, -6.8185e-03,  6.3231e-02,  3.7147e-02, -2.5756e-02,\n",
      "          1.3091e-01, -4.1528e-02]], dtype=torch.float64)), ('fc1.bias', tensor([-0.1568, -0.2279,  0.2312,  0.2039,  0.0587,  0.2470,  0.0154, -0.0399,\n",
      "        -0.1327, -0.0859,  0.0810,  0.0737, -0.1619, -0.2584,  0.0661, -0.0235,\n",
      "         0.1553,  0.1290,  0.0150,  0.1981, -0.0324,  0.1594, -0.0489, -0.0063,\n",
      "         0.0442,  0.0105,  0.1636, -0.1607,  0.0158,  0.1010,  0.0848, -0.0350,\n",
      "        -0.0726, -0.1616,  0.0913,  0.1535, -0.1257,  0.2185, -0.0217, -0.0299,\n",
      "        -0.0274,  0.0852,  0.1125,  0.1767, -0.1482, -0.0188,  0.1483,  0.0248,\n",
      "        -0.0017, -0.0762,  0.1852,  0.0932,  0.0071, -0.1180, -0.0259,  0.0469,\n",
      "        -0.1171, -0.0884, -0.0218,  0.1125,  0.2155,  0.0468, -0.1701,  0.0564],\n",
      "       dtype=torch.float64)), ('fc2.weight', tensor([[-0.0169,  0.0078,  0.0065,  ..., -0.0178, -0.0179,  0.0095],\n",
      "        [ 0.0197,  0.0094,  0.0174,  ...,  0.0083, -0.0015,  0.0072],\n",
      "        [-0.0051, -0.0030, -0.0110,  ...,  0.0034, -0.0010, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0046,  0.0092, -0.0021,  ...,  0.0033,  0.0109, -0.0165],\n",
      "        [-0.0042,  0.0020, -0.0062,  ...,  0.0020,  0.0084, -0.0059],\n",
      "        [ 0.0044,  0.0040,  0.0026,  ...,  0.0032,  0.0012,  0.0005]],\n",
      "       dtype=torch.float64)), ('fc2.bias', tensor([ 2.2814e-02,  3.8684e-02,  7.0541e-04,  3.2752e-02,  4.9039e-02,\n",
      "        -1.7970e-02, -1.2225e-02,  1.0822e-02,  6.1314e-02,  1.1761e-02,\n",
      "        -6.7199e-03,  5.5994e-19,  7.3077e-03,  7.9440e-03,  4.4632e-02,\n",
      "        -7.1679e-04,  2.8945e-02, -4.5773e-03,  3.3093e-02,  1.0343e-02,\n",
      "        -2.8065e-02,  3.7491e-02,  1.7686e-02,  3.9809e-02,  3.4907e-03,\n",
      "         1.9895e-02,  3.0741e-02,  6.4160e-02, -2.2087e-03, -6.5922e-03,\n",
      "         2.4571e-02, -2.9543e-09, -3.5234e-03,  5.4108e-02,  5.4766e-03,\n",
      "         2.9659e-02,  2.4443e-02, -2.5338e-02, -8.2200e-03, -1.5839e-03,\n",
      "         2.7692e-02, -1.0771e-03,  5.7836e-05,  1.7643e-02, -4.2053e-03,\n",
      "         5.7198e-02,  2.9501e-02,  5.6022e-02, -3.1474e-02,  9.3802e-02,\n",
      "        -1.1426e-03,  8.2949e-02, -1.2598e-03,  1.6006e-02,  2.2458e-02,\n",
      "         1.1099e-02, -8.5624e-03,  6.7151e-15,  1.6948e-03, -3.0173e-04,\n",
      "        -6.1043e-02, -1.3251e-02,  7.0937e-03,  1.2324e-05, -2.2239e-02,\n",
      "         4.6193e-03,  2.1087e-03,  9.4388e-03,  1.5898e-02,  3.8539e-02,\n",
      "         2.6299e-02, -2.1786e-02, -3.2886e-02, -1.5986e-02, -8.8143e-03,\n",
      "        -3.3033e-03,  2.7219e-02,  2.4679e-02,  9.6829e-03,  2.3725e-02,\n",
      "         1.7224e-02, -3.9564e-03,  1.7821e-02, -1.2568e-02, -1.1620e-02,\n",
      "        -7.4983e-03,  4.4688e-02, -3.2750e-03, -5.2481e-04,  1.9779e-02,\n",
      "         1.8934e-03,  9.0940e-03,  2.1861e-02,  4.4331e-02, -1.1600e-02,\n",
      "        -3.5246e-03,  3.6897e-02, -8.8764e-03,  4.9278e-03, -3.1141e-06,\n",
      "        -8.8525e-03,  3.4782e-03, -2.9846e-02, -7.4635e-04,  3.8889e-02,\n",
      "        -1.9459e-01,  7.0483e-02, -7.3669e-03,  6.5392e-03, -1.7385e-02,\n",
      "         4.2577e-02, -2.3838e-04,  1.4187e-02, -2.4453e-01,  3.5540e-02,\n",
      "         4.4435e-03,  3.3694e-02, -1.4595e-02, -7.3883e-03,  6.3992e-02,\n",
      "         3.3766e-02, -1.2634e-03,  4.6061e-02,  1.7021e-02,  3.4804e-02,\n",
      "         3.3541e-02,  5.5850e-02,  7.7928e-02,  1.6945e-03,  3.5336e-03,\n",
      "         3.7419e-03, -6.0905e-03,  5.5752e-03, -1.3144e-02,  1.7919e-02,\n",
      "         1.1536e-02, -2.9281e-02,  2.6949e-03,  8.7366e-03, -1.1574e-04,\n",
      "        -1.6867e-02,  9.2969e-03, -5.0355e-04,  3.1302e-03, -3.5260e-02,\n",
      "        -1.7416e-02, -2.8454e-02,  3.4497e-04,  2.1144e-02,  7.9032e-02,\n",
      "         1.3722e-02,  7.3597e-03,  2.0572e-19, -2.5897e-03, -2.6600e-03,\n",
      "         1.6147e-02,  3.3800e-02, -1.4286e-01,  3.7288e-02,  7.0049e-03,\n",
      "         4.6563e-20,  6.1584e-02,  2.3645e-02,  5.2982e-02,  1.6297e-02,\n",
      "        -4.1859e-03, -1.1728e-02,  2.2415e-02, -4.7154e-04,  3.1780e-02,\n",
      "        -1.9034e-02,  1.5394e-02, -2.4570e-03,  2.8095e-02,  4.2273e-02,\n",
      "        -2.0236e-05, -2.2423e-03,  2.8412e-02, -3.1496e-02,  6.3365e-02,\n",
      "         1.3951e-02, -8.2964e-04, -1.4101e-02, -1.3257e-03, -4.3022e-03,\n",
      "         5.7877e-02,  2.9657e-02,  1.8467e-02, -2.3199e-03,  3.0332e-02,\n",
      "         2.7198e-06,  2.2644e-02,  2.6548e-02, -6.4520e-04, -2.2064e-04,\n",
      "         9.4106e-02,  1.6093e-02, -1.3325e-02,  1.1771e-02, -3.6956e-02,\n",
      "        -2.1297e-05, -2.3706e-02,  1.2338e-02,  6.0579e-02, -9.3293e-03,\n",
      "         4.3828e-04,  3.3054e-02,  2.8077e-02,  3.0938e-02,  8.5568e-03,\n",
      "         2.0937e-02,  5.5738e-03, -6.5224e-03,  2.5362e-02,  3.3545e-02,\n",
      "         1.1581e-02,  2.9495e-02,  8.9247e-04, -1.8350e-04,  3.5178e-02,\n",
      "         3.1030e-02, -2.3688e-02,  3.4184e-03,  2.6548e-02, -1.3914e-02,\n",
      "         5.5752e-02, -1.4120e-02,  3.0095e-02, -1.3910e-03,  3.6284e-03,\n",
      "        -5.2795e-03, -3.7148e-03, -4.8585e-03,  3.0954e-03,  1.0725e-02,\n",
      "         1.4167e-02, -2.0495e-02,  1.8015e-02, -1.6649e-04, -4.5746e-14,\n",
      "         1.9048e-02, -7.5395e-03,  4.7712e-04,  1.2591e-01, -2.3831e-02,\n",
      "        -2.5494e-05, -8.5999e-04,  3.6832e-02, -2.1343e-02, -5.5585e-03,\n",
      "        -1.9728e-04,  3.5025e-02,  4.5617e-02,  6.2386e-02,  5.8726e-02,\n",
      "         1.7712e-02, -2.3434e-02,  2.7098e-02,  5.2256e-02, -5.6567e-04,\n",
      "         6.0089e-03,  4.9646e-02, -2.2771e-03,  4.2913e-03,  3.6476e-02,\n",
      "        -1.7954e-02,  4.3589e-02,  2.9871e-02, -2.8582e-02, -8.7053e-03,\n",
      "        -3.1623e-03,  1.2058e-02,  1.2419e-03,  8.9093e-03,  6.2618e-04,\n",
      "        -3.8148e-01, -4.4070e-03,  5.2634e-02,  2.3796e-02, -4.0472e-02,\n",
      "         5.1248e-05, -2.6801e-03, -3.1271e-02,  3.0503e-02,  1.5641e-02,\n",
      "         4.4711e-03,  1.6022e-02,  2.4819e-02,  4.8559e-03,  2.9685e-04,\n",
      "         1.3722e-02,  1.1159e-02,  3.8213e-03,  2.1831e-02, -1.3565e-02,\n",
      "         7.9309e-15, -3.5692e-02, -2.0649e-03,  1.7159e-06,  4.8622e-02,\n",
      "         1.5486e-02, -1.4334e-02,  1.6544e-02, -9.8905e-15, -7.1209e-04,\n",
      "        -1.3053e-02,  2.3558e-03, -2.7034e-02, -1.0578e-03,  1.3018e-02,\n",
      "        -7.8081e-02, -6.9864e-04, -2.3629e-03, -7.9232e-03, -1.1668e-03,\n",
      "        -5.1173e-17,  3.0449e-02, -2.8721e-03, -5.7265e-03,  4.1423e-02,\n",
      "         8.0166e-02,  2.6912e-02,  7.3792e-03,  3.3660e-02,  2.2874e-02,\n",
      "        -8.0133e-04,  7.8586e-04,  2.2874e-02, -2.3855e-02, -5.5681e-03,\n",
      "        -3.3835e-03, -1.2127e-03, -2.7087e-02,  2.2064e-02, -4.8477e-16,\n",
      "         1.9842e-02, -2.8118e-05,  3.2012e-02, -2.5860e-02, -8.2144e-03,\n",
      "        -1.7684e-02,  2.3394e-02,  1.6194e-02,  2.5473e-02,  2.4349e-03,\n",
      "         1.5927e-02,  3.6616e-02,  1.6845e-02,  1.7588e-02, -1.8777e-03,\n",
      "         2.4242e-02,  1.8340e-02,  1.8865e-02, -3.2834e-02,  6.3261e-02,\n",
      "        -3.5020e-02,  1.0904e-01,  5.1005e-02, -2.7918e-02,  4.7015e-02,\n",
      "         3.5393e-02,  1.2725e-02,  2.7951e-02,  6.0238e-02,  9.0890e-09,\n",
      "         1.3212e-03, -1.8679e-03,  1.5175e-02,  2.4113e-02, -5.7720e-04,\n",
      "         2.6828e-04,  2.9719e-02,  5.0993e-02,  1.7604e-02, -1.0851e-02,\n",
      "        -2.6273e-02,  1.0174e-01,  5.8539e-03, -2.3032e-12,  9.5341e-05,\n",
      "        -3.4381e-02,  7.6763e-02,  2.0000e-03,  4.0098e-03, -3.0816e-02,\n",
      "        -1.5642e-02,  1.5330e-03,  1.4432e-02, -9.3870e-03,  8.9331e-02,\n",
      "         9.1581e-10,  3.0651e-09,  2.6839e-02,  4.1554e-02,  1.7485e-03,\n",
      "         1.0570e-01, -3.5836e-03,  1.2788e-01, -5.6950e-04, -1.8377e-16,\n",
      "         1.4751e-05, -1.7236e-02,  5.1256e-03,  8.0991e-02,  5.5662e-03,\n",
      "        -2.7642e-03,  2.6681e-02, -1.3258e-05,  2.4428e-02, -5.4983e-04,\n",
      "        -1.8679e-01,  1.4713e-02,  2.2735e-02,  2.1894e-02,  4.0519e-02,\n",
      "         3.4209e-02,  1.1049e-02,  9.6797e-03, -9.3144e-18,  1.5032e-02,\n",
      "        -7.7592e-03,  3.1928e-02,  1.3061e-02, -2.7493e-03,  3.6248e-02,\n",
      "         6.3829e-03,  9.4279e-03, -2.3356e-03,  1.7986e-02,  4.0846e-04,\n",
      "         4.9438e-02,  3.9021e-02, -4.2629e-18, -1.8076e-02, -1.5341e-03,\n",
      "         5.3748e-02,  2.8559e-02,  1.2517e-03,  2.1252e-02, -4.9475e-04,\n",
      "        -2.4504e-04,  2.9007e-02,  3.4543e-02, -2.0153e-03,  2.5693e-03,\n",
      "         5.0496e-02,  1.2782e-02, -2.3715e-17, -3.3561e-05,  3.1493e-02,\n",
      "         4.6526e-03,  8.4451e-03, -2.8968e-03,  4.0452e-02,  4.2640e-03,\n",
      "         3.8596e-02,  2.7658e-02,  4.6866e-02,  9.8593e-03,  3.2008e-02,\n",
      "        -2.1539e-02,  5.4846e-02,  1.7367e-02, -1.7738e-04, -5.5487e-04,\n",
      "        -2.3216e-02,  7.2957e-03, -1.0561e-02, -1.3502e-02,  2.5618e-02,\n",
      "         8.1946e-03,  2.9043e-02,  3.8760e-02, -1.9364e-02, -1.8126e-02,\n",
      "         3.0957e-02, -5.4827e-03, -8.0192e-03, -7.3133e-03,  6.6760e-02,\n",
      "        -2.1199e-03,  3.0741e-04, -9.3931e-08, -1.1984e-02,  2.3529e-03,\n",
      "         4.7009e-02, -5.2614e-03,  9.8727e-03, -8.1503e-03,  2.9379e-02,\n",
      "        -8.8680e-03,  4.0567e-03,  6.9141e-02, -4.6155e-03, -8.1533e-03,\n",
      "         3.9038e-03,  2.4759e-02,  7.7924e-02, -3.0880e-02, -1.4209e-03,\n",
      "        -2.6246e-02,  3.4685e-02,  2.8306e-02, -2.8441e-02, -1.4362e-02,\n",
      "         3.9387e-02, -1.4701e-03,  4.2924e-02, -1.1852e-04,  1.6579e-02,\n",
      "        -9.7852e-04,  1.5032e-02], dtype=torch.float64)), ('fc3.weight', tensor([[ 0.0221,  0.0178,  0.0067,  ..., -0.0055, -0.0028,  0.0035],\n",
      "        [ 0.0336,  0.0011,  0.0112,  ..., -0.0062, -0.0047,  0.0060],\n",
      "        [-0.0150,  0.0005, -0.0047,  ...,  0.0074,  0.0040,  0.0173],\n",
      "        ...,\n",
      "        [-0.0165,  0.0152, -0.0036,  ...,  0.0076,  0.0051,  0.0179],\n",
      "        [ 0.0191,  0.0057,  0.0055,  ..., -0.0047, -0.0023,  0.0012],\n",
      "        [-0.0363,  0.0131, -0.0095,  ...,  0.0155,  0.0047, -0.0064]],\n",
      "       dtype=torch.float64)), ('fc3.bias', tensor([ 1.8725e-02,  3.6887e-03,  4.3213e-02,  1.3347e-02, -6.7803e-03,\n",
      "         1.6939e-02,  5.6366e-02,  3.6732e-03,  4.4079e-02,  3.8776e-02,\n",
      "         6.7047e-02, -1.7850e-03, -7.8815e-04,  4.2071e-03,  1.6616e-03,\n",
      "         4.0782e-02,  1.4961e-02, -1.9746e-02,  3.3621e-03,  2.2750e-02,\n",
      "         1.6316e-02,  3.0779e-02,  1.3341e-02,  5.6455e-03,  5.6231e-03,\n",
      "         5.9530e-03,  4.7148e-02,  4.5270e-02,  4.3070e-03,  4.0632e-02,\n",
      "         4.2927e-02,  1.8987e-02,  1.8891e-02,  2.0826e-04,  9.5876e-03,\n",
      "         4.2662e-02,  1.6825e-02,  2.7528e-02,  2.6214e-02, -1.4049e-02,\n",
      "         4.8003e-02,  2.4382e-02, -2.0000e-07,  6.0473e-02,  1.0567e-02,\n",
      "         5.3351e-03, -1.1316e-02,  2.3629e-02,  2.3389e-02, -1.9245e-03,\n",
      "         2.0041e-02,  2.5189e-03,  3.8003e-02,  3.4104e-02,  2.2607e-02,\n",
      "         5.5221e-03,  2.6859e-02, -6.7865e-03, -4.7301e-09, -8.6161e-03,\n",
      "         4.5336e-02,  4.6943e-03,  2.7529e-02,  4.9826e-02],\n",
      "       dtype=torch.float64)), ('fc4.weight', tensor([[ 9.8496e-02,  1.4968e-01, -8.6965e-02, -9.0017e-02, -9.2057e-03,\n",
      "         -1.4741e-01,  1.5617e-01, -3.3977e-02,  1.4854e-01,  8.4754e-02,\n",
      "          2.9634e-01, -1.8208e-03, -2.8088e-05,  8.6778e-03, -4.6221e-02,\n",
      "          1.3857e-01, -7.3295e-02,  3.1112e-02,  7.3928e-03,  1.5509e-01,\n",
      "          4.8364e-02,  1.0833e-01,  9.8328e-02, -4.5289e-02,  1.3077e-01,\n",
      "         -7.7683e-02,  1.8609e-01, -1.5878e-01,  4.0799e-02, -2.0359e-01,\n",
      "         -8.9387e-02, -8.3108e-02,  5.3287e-02,  4.7233e-02, -6.7238e-02,\n",
      "          1.2596e-01,  7.9258e-02,  2.5660e-01, -3.7203e-02, -3.0124e-02,\n",
      "         -1.8863e-01, -1.8351e-01,  4.6800e-03,  1.8356e-01,  2.2085e-01,\n",
      "         -1.5847e-01,  3.0713e-01,  8.1631e-02, -7.0062e-02,  1.3402e-01,\n",
      "         -5.0523e-02,  1.3681e-01, -7.8258e-02, -5.1222e-02, -1.0838e-01,\n",
      "         -5.8034e-02, -1.9721e-01,  1.3765e-01,  1.6000e-08, -1.5628e-01,\n",
      "         -1.4089e-01, -9.1044e-02,  8.5574e-02, -1.9857e-01]],\n",
      "       dtype=torch.float64)), ('fc4.bias', tensor([0.0550], dtype=torch.float64))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb6f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
